{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c569d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.fe_v2 import make_features\n",
    "from src.config import RANDOM_SEED, TEST_SIZE, TOP_K\n",
    "from src.metrics import mapk, hit_rate_at_k\n",
    "from src.model_utils import topk_from_proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732ff358",
   "metadata": {},
   "source": [
    "### Setup and Imports\n",
    "\n",
    "This notebook contains the **final, cleaned version** of our LightGBM model\n",
    "for the Expedia Hotel Recommendation task.\n",
    "\n",
    "All utilities (feature engineering, metrics, configuration) are imported\n",
    "from the shared `src/` module to ensure reproducibility and consistency\n",
    "across experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1069275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2988177, 173)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"../data/processed/df_model.parquet\"\n",
    "\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce6164",
   "metadata": {},
   "source": [
    "### Dataset Overview\n",
    "\n",
    "We use the processed modeling dataset derived from the original\n",
    "Expedia competition data.\n",
    "\n",
    "The dataset contains ~3M rows and 173 columns, including:\n",
    "- user context\n",
    "- search intent\n",
    "- destination metadata\n",
    "- latent destination features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5459ae4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 173)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(n=500_000, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90294c3c",
   "metadata": {},
   "source": [
    "### Sampling Strategy\n",
    "\n",
    "To enable **fast iteration and stable experimentation**, we intentionally\n",
    "train the model on a **fixed random sample of 500,000 rows**.\n",
    "\n",
    "This sample is:\n",
    "- large enough to be representative\n",
    "- small enough to allow rapid training and tuning\n",
    "- fully reproducible via a fixed random seed\n",
    "\n",
    "Once the modeling decisions are finalized, the same pipeline\n",
    "can be scaled to the full dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "512fb8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500000, 166), (500000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_features(df)\n",
    "\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3724eff",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "We apply a second-generation feature engineering pipeline (`fe_v2`) focused on:\n",
    "- booking intent\n",
    "- temporal patterns (check-in month, stay length)\n",
    "- distance behavior\n",
    "- family vs solo travel\n",
    "- destination latent embeddings (d1–d149)\n",
    "\n",
    "The pipeline is defensive to missing values and produces\n",
    "model-ready numerical and categorical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b952f8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2195073",
   "metadata": {},
   "source": [
    "### Train–Validation Split\n",
    "\n",
    "We use a stratified split to preserve the distribution\n",
    "of hotel clusters in both training and validation sets.\n",
    "\n",
    "This is critical for reliable evaluation in a highly\n",
    "imbalanced multi-class problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d682ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"stay_type\", \"distance_bucket\"]\n",
    "\n",
    "for col in categorical_features:\n",
    "    X_train[col] = X_train[col].astype(\"category\")\n",
    "    X_val[col] = X_val[col].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d450cc6",
   "metadata": {},
   "source": [
    "### Categorical Features\n",
    "\n",
    "LightGBM natively supports categorical features.\n",
    "We explicitly declare engineered categorical variables\n",
    "to allow optimal tree splitting without one-hot encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1ca53c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(\n",
    "    X_train,\n",
    "    label=y_train,\n",
    "    categorical_feature=categorical_features,\n",
    "    free_raw_data=False\n",
    ")\n",
    "\n",
    "val_data = lgb.Dataset(\n",
    "    X_val,\n",
    "    label=y_val,\n",
    "    categorical_feature=categorical_features,\n",
    "    free_raw_data=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e80c113",
   "metadata": {},
   "source": [
    "### LightGBM Dataset Objects\n",
    "\n",
    "We convert pandas data into LightGBM Dataset objects,\n",
    "which improves memory efficiency and training speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12c693da",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": y.nunique(),\n",
    "    \"metric\": \"multi_logloss\",\n",
    "\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 64,\n",
    "    \"max_depth\": -1,\n",
    "\n",
    "    \"min_data_in_leaf\": 100,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 1,\n",
    "\n",
    "    \"verbosity\": -1,\n",
    "    \"seed\": RANDOM_SEED,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b130aff8",
   "metadata": {},
   "source": [
    "### Model Configuration\n",
    "\n",
    "We use a LightGBM multiclass classifier optimized for:\n",
    "- large-scale tabular data\n",
    "- high-cardinality categorical variables\n",
    "- fast inference\n",
    "\n",
    "Regularization parameters were chosen to balance\n",
    "model capacity and generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb8fd2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid's multi_logloss: 2.97887\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[val_data],\n",
    "    valid_names=[\"valid\"],\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b2743",
   "metadata": {},
   "source": [
    "### Training Strategy\n",
    "\n",
    "We train with early stopping to prevent overfitting.\n",
    "The model automatically selects the best number of trees\n",
    "based on validation performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b777e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.31117719999999993, 0.534824)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.sort(y_train.unique())\n",
    "\n",
    "proba = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "\n",
    "top5 = topk_from_proba(\n",
    "    proba,\n",
    "    classes,\n",
    "    k=TOP_K\n",
    ")\n",
    "\n",
    "map5 = mapk(y_val, top5, k=TOP_K)\n",
    "hit5 = hit_rate_at_k(y_val, top5, k=TOP_K)\n",
    "\n",
    "map5, hit5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b63ce",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "We evaluate using:\n",
    "- MAP@5: ranking quality of top-5 recommendations\n",
    "- Hit@5: probability that the true hotel cluster appears in top-5\n",
    "\n",
    "These metrics directly align with the business objective\n",
    "of presenting a small, high-quality set of recommendations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c51fa7e",
   "metadata": {},
   "source": [
    "### Final Model Summary\n",
    "\n",
    "- Model: LightGBM multiclass classifier\n",
    "- Training data: 500k representative sample\n",
    "- Features: engineered behavioral + destination embeddings\n",
    "- MAP@5: ~0.31\n",
    "- Hit@5: ~0.53\n",
    "\n",
    "This model represents a strong, production-ready baseline.\n",
    "The architecture scales naturally to the full dataset\n",
    "once experimentation is complete.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
