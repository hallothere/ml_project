{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53693d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.fe_v1 import make_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07b83d",
   "metadata": {},
   "source": [
    "# Expedia Hotel Recommendation Model  \n",
    "## Gradient Boosted Decision Trees (LightGBM)\n",
    "\n",
    "**Goal:**  \n",
    "Predict and rank the hotel clusters a user is most likely to book.\n",
    "\n",
    "**Why this model?**\n",
    "- Tabular data\n",
    "- Mixed feature types (numeric + categorical)\n",
    "- Non-linear relationships\n",
    "- Strong baseline for real-world recommender systems\n",
    "\n",
    "This notebook trains a **LightGBM multiclass model** and evaluates it using **MAP@5**, aligned with the Kaggle metric and Expedia’s product reality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e765a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "\n",
    "from src.fe_v1 import make_features\n",
    "from src.config import RANDOM_SEED, TEST_SIZE, TOP_K\n",
    "from src.metrics import mapk, hit_rate_at_k\n",
    "from src.model_utils import topk_from_proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f21081d",
   "metadata": {},
   "source": [
    "We load shared project utilities to ensure consistency across experiments.\n",
    "Feature engineering, metrics, and configuration are reused to keep results comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6499044e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2988177, 173)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"../data/processed/df_model.parquet\"\n",
    "\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22dc99ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 173)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(n=500_000, random_state=42).reset_index(drop=True)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc1b57",
   "metadata": {},
   "source": [
    "We work on processed, cleaned data\n",
    "Heavy raw preprocessing was already done in make_dataset.py\n",
    "This keeps the notebook fast and focused on modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21598329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500000, 17), (500000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_features(df)\n",
    "\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ebe29",
   "metadata": {},
   "source": [
    "Feature engineering is centralized in fe_v1.py to avoid duplication and ensure all models use the same feature logic.\n",
    "Key feature groups:\n",
    "User geography\n",
    "Search intent\n",
    "Time & stay characteristics\n",
    "Distance behavior\n",
    "Commercial context (package, channel, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ec3e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stay_type', 'distance_missing', 'distance_bucket']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = X.select_dtypes(include=[\"object\", \"bool\"]).columns.tolist()\n",
    "categorical_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7a6e9d",
   "metadata": {},
   "source": [
    "LightGBM:\n",
    "handles categorical features natively\n",
    "no one-hot encoding needed\n",
    "faster & more memory-efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c19d15c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((375000, 17), (125000, 17))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_val.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4328af7e",
   "metadata": {},
   "source": [
    "Stratified split keeps hotel cluster distribution stable\n",
    "Prevents rare clusters from disappearing in validation\n",
    "Reflects real production behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e00e0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(\n",
    "    X_train,\n",
    "    label=y_train,\n",
    "    categorical_feature=categorical_features,\n",
    "    free_raw_data=False,\n",
    ")\n",
    "\n",
    "val_data = lgb.Dataset(\n",
    "    X_val,\n",
    "    label=y_val,\n",
    "    categorical_feature=categorical_features,\n",
    "    free_raw_data=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce4076f",
   "metadata": {},
   "source": [
    "LightGBM uses its own optimized data format for:\n",
    "speed\n",
    "memory efficiency\n",
    "large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25e8a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": y.nunique(),\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 63,\n",
    "    \"max_depth\": -1,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"seed\": RANDOM_SEED,\n",
    "    \"verbosity\": -1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1776419e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.6.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgb.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3620231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell LightGBM which features are categorical\n",
    "categorical_features = [\"stay_type\", \"distance_bucket\"]\n",
    "\n",
    "for col in categorical_features:\n",
    "    X_train[col] = X_train[col].astype(\"category\")\n",
    "    X_val[col] = X_val[col].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a0f37b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(\n",
    "    X_train,\n",
    "    label=y_train,\n",
    "    categorical_feature=categorical_features,\n",
    "    free_raw_data=False,\n",
    ")\n",
    "\n",
    "val_data = lgb.Dataset(\n",
    "    X_val,\n",
    "    label=y_val,\n",
    "    categorical_feature=categorical_features,\n",
    "    free_raw_data=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2335d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aipm-1711/ml project/ml_project/.venv/lib/python3.11/site-packages/lightgbm/engine.py:322\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[32m    311\u001b[39m     cb(\n\u001b[32m    312\u001b[39m         callback.CallbackEnv(\n\u001b[32m    313\u001b[39m             model=booster,\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m         )\n\u001b[32m    320\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mbooster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] = []\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aipm-1711/ml project/ml_project/.venv/lib/python3.11/site-packages/lightgbm/basic.py:4155\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, train_set, fobj)\u001b[39m\n\u001b[32m   4152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__set_objective_to_none:\n\u001b[32m   4153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[33m\"\u001b[39m\u001b[33mCannot update due to null objective function.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4154\u001b[39m _safe_call(\n\u001b[32m-> \u001b[39m\u001b[32m4155\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4159\u001b[39m )\n\u001b[32m   4160\u001b[39m \u001b[38;5;28mself\u001b[39m.__is_predicted_cur_iter = [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.__num_dataset)]\n\u001b[32m   4161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished.value == \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data, val_data],\n",
    "    valid_names=[\"train\", \"valid\"],\n",
    "    num_boost_round=500,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce55eb58",
   "metadata": {},
   "source": [
    "Train up to 500 trees\n",
    "Stop early if validation stops improving\n",
    "Prevents overfitting automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc5b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_val = model.predict(X_val)\n",
    "classes = model.classes_ if hasattr(model, \"classes_\") else np.arange(y.nunique())\n",
    "\n",
    "topk_preds = topk_from_proba(proba_val, classes, k=TOP_K)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b7fe92",
   "metadata": {},
   "source": [
    "Model outputs probabilities\n",
    "Product needs ranked recommendations\n",
    "We convert probabilities → top-5 hotel clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8707ff23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20825066666666667, 0.372656)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map5 = mapk(y_val.values, topk_preds, k=TOP_K)\n",
    "hit5 = hit_rate_at_k(y_val.values, topk_preds, k=TOP_K)\n",
    "\n",
    "map5, hit5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8757d7f4",
   "metadata": {},
   "source": [
    "MAP@5 → ranking quality (main KPI)\n",
    "Hit@5 → how often correct cluster appears anywhere in top 5\n",
    "Together they give a realistic view of recommendation quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e8cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"importance\": model.feature_importance()\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "importance_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e704f",
   "metadata": {},
   "source": [
    "Explains why model makes decisions\n",
    "Confirms EDA insights (geo, destination, distance)\n",
    "Helps trust & stakeholder communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bff9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.fe_v2 import make_features\n",
    "from src.config import RANDOM_SEED, TEST_SIZE, TOP_K\n",
    "from src.metrics import mapk, hit_rate_at_k\n",
    "from src.model_utils import topk_from_proba\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
